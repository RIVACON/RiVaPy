{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Librarieres für RiVaPy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rivapy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.5f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benötigte Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "TransMat = np.matrix(\"\"\"\n",
    "90.81, 8.33, 0.68, 0.06, 0.08, 0.02, 0.01, 0.01;\n",
    "0.70, 90.65, 7.79, 0.64, 0.06, 0.13, 0.02, 0.01;\n",
    "0.09, 2.27, 91.05, 5.52, 0.74, 0.26, 0.01, 0.06;\n",
    "0.02, 0.33, 5.95, 85.93, 5.30, 1.17, 1.12, 0.18;\n",
    "0.03, 0.14, 0.67, 7.73, 80.53, 8.84, 1.00, 1.06;\n",
    "0.01, 0.11, 0.24, 0.43, 6.48, 83.46, 4.07, 5.20;\n",
    "0.21, 0, 0.22, 1.30, 2.38, 11.24, 64.86, 19.79\"\"\")/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pd.read_excel(\"C:/Users/Anwender/Desktop/Datenmodell_Krediportfoliomodell.xlsx\", \"Positions\")\n",
    "issuer = pd.read_excel(\"C:/Users/Anwender/Desktop/Datenmodell_Krediportfoliomodell.xlsx\", \"Issuer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsim = 5000 # num sim for CVaR\n",
    "r = 0 # risk free rate\n",
    "t= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketDataDAX = pd.read_excel(\"C:/Users/Anwender/Desktop/^GDAXI.xlsx\", \"DAX\").rename(columns={\"Close\" : \"Dax\"})\n",
    "marketDataBASF = pd.read_excel(\"C:/Users/Anwender/Desktop/^GDAXI.xlsx\", \"BASF\").rename(columns={\"Close\" : \"BASF\"})\n",
    "marketDataLHA = pd.read_excel(\"C:/Users/Anwender/Desktop/^GDAXI.xlsx\", \"Lufthansa\").rename(columns={\"Close\" : \"LHA\"})\n",
    "marketDataVW = pd.read_excel(\"C:/Users/Anwender/Desktop/^GDAXI.xlsx\", \"Volkswagen\").rename(columns={\"Close\" : \"VW\"})\n",
    "marketDataDAX = marketDataDAX[marketDataDAX[\"Date\"]>='2007-04-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData = marketDataDAX[['Date', 'Dax']].merge(marketDataBASF[['Date', 'BASF']], on='Date', how='left').merge(marketDataLHA[['Date', 'LHA']], on='Date', how='left').merge(marketDataVW[['Date', 'VW']], on='Date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutzung Credit Metrics Modell innerhalb RiVaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rivapy.credit.creditMetricsModel(5, TransMat, positions, issuer, mergedData, r, t, 0.55, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15775.2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(tmp, 30 , interpolation = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15775.2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-19719.00000+(0-(-19719.00000))*((0.3-0.25)/(0.5-0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erste Überlegungen Korrelationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import sys\n",
    "import math\n",
    "from scipy.linalg import sqrtm\n",
    "from random import seed\n",
    "from random import random\n",
    "import plotly.express as px\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "import rivapy\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "from numpy.linalg import cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickerStrings = ['DLAKY', 'VLKPF', 'SAP', 'MRK']\n",
    "df_list = list()\n",
    "for ticker in tickerStrings:\n",
    "    # data = yf.download(ticker, group_by=\"Ticker\", start='2007-04-02',end='2022-03-14')\n",
    "    data = pdr.get_data_yahoo(ticker, group_by=\"Ticker\", start='2012-03-11',end='2022-03-14')[[ 'Close']].rename(columns = {'Close' : ('Close_'+ticker)})\n",
    "    # data['ticker'] = ticker  # add this column because the dataframe doesn't contain a column with the ticker\n",
    "    df_list.append(data)\n",
    "\n",
    "# combine all dataframes into a single dataframe\n",
    "# df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dax</th>\n",
       "      <th>BASF</th>\n",
       "      <th>LHA</th>\n",
       "      <th>VW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.028236</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>0.005050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018091</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>0.025480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004846</td>\n",
       "      <td>-0.020868</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>-0.024497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018791</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>-0.007658</td>\n",
       "      <td>-0.008969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>-0.024804</td>\n",
       "      <td>-0.020818</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>-0.051020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>-0.031596</td>\n",
       "      <td>-0.101546</td>\n",
       "      <td>-0.046191</td>\n",
       "      <td>-0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>-0.101096</td>\n",
       "      <td>-0.152739</td>\n",
       "      <td>-0.195241</td>\n",
       "      <td>-0.183775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.040748</td>\n",
       "      <td>0.052344</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.024341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.055763</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>0.054881</td>\n",
       "      <td>0.081188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dax      BASF       LHA        VW\n",
       "0         NaN       NaN       NaN       NaN\n",
       "1    0.015797  0.028236  0.029316  0.005050\n",
       "2    0.018091  0.004371 -0.002713  0.025480\n",
       "3    0.004846 -0.020868  0.006346 -0.024497\n",
       "4    0.018791  0.005471 -0.007658 -0.008969\n",
       "..        ...       ...       ...       ...\n",
       "776 -0.024804 -0.020818 -0.001326 -0.051020\n",
       "777 -0.031596 -0.101546 -0.046191 -0.000827\n",
       "778 -0.101096 -0.152739 -0.195241 -0.183775\n",
       "779  0.040748  0.052344  0.153208  0.024341\n",
       "780  0.055763  0.012621  0.054881  0.081188\n",
       "\n",
       "[781 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedData = mergedData.drop(['Date'], axis=1)\n",
    "returns = mergedData.pct_change()\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dax</th>\n",
       "      <th>BASF</th>\n",
       "      <th>LHA</th>\n",
       "      <th>VW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dax</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865773</td>\n",
       "      <td>0.613133</td>\n",
       "      <td>0.508473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASF</th>\n",
       "      <td>0.865773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570253</td>\n",
       "      <td>0.404331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LHA</th>\n",
       "      <td>0.613133</td>\n",
       "      <td>0.570253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VW</th>\n",
       "      <td>0.508473</td>\n",
       "      <td>0.404331</td>\n",
       "      <td>0.279816</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dax      BASF       LHA        VW\n",
       "Dax   1.000000  0.865773  0.613133  0.508473\n",
       "BASF  0.865773  1.000000  0.570253  0.404331\n",
       "LHA   0.613133  0.570253  1.000000  0.279816\n",
       "VW    0.508473  0.404331  0.279816  1.000000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_mat = returns.corr()\n",
    "correlation_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8657731142064324\n"
     ]
    }
   ],
   "source": [
    "corr_pairs = correlation_mat.unstack()\n",
    "\n",
    "print(corr_pairs['Dax','BASF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dax     1.000000\n",
       "BASF    0.865773\n",
       "LHA     0.613133\n",
       "VW      0.508473\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_pairs['Dax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation (stockData):\n",
    "    mergedData = stockData.drop(['Date'], axis=1)\n",
    "    returns = mergedData.pct_change()\n",
    "\n",
    "    correlation_mat = returns.corr()\n",
    "    corr_pairs = correlation_mat.unstack()['Dax']\n",
    "    return(corr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen außerhalb RiVaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_map = pd.DataFrame({'Rating': [\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC\", \"D\"], 'RatingID': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
    "issuer_adj = issuer.merge(rating_map, on = \"Rating\", how = \"left\")\n",
    "positions_adj = positions.merge(issuer_adj[[\"IssuerID\",\"Rating\",\"RatingID\"]], on = \"IssuerID\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergePositionsIssuer(position_data, issuer_data):\n",
    "    rating_map = pd.DataFrame({'Rating': [\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC\", \"D\"], 'RatingID': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
    "    issuer_adj = issuer_data.merge(rating_map, on = \"Rating\", how = \"left\")\n",
    "    positions_adj = positions.merge(issuer_adj[[\"IssuerID\",\"Rating\",\"RatingID\"]], on = \"IssuerID\", how = \"left\")\n",
    "\n",
    "    return positions_adj\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_matrix (rho, n):\n",
    "    sigma = rho*np.ones((n,n))\n",
    "    sigma = sigma -np.diag(np.diag(sigma)) + np.eye(n)\n",
    "    return sigma\n",
    "\n",
    "def get_cutoffs_rating(transition_matrix):\n",
    "    Z=np.cumsum(np.flipud(transition_matrix.T),0)\n",
    "    Z[Z>=(1-1/1e12)] = 1-1/1e12;\n",
    "    Z[Z<=(0+1/1e12)] = 0+1/1e12;\n",
    "\n",
    "    CutOffs=norm.ppf(Z,0,1) # compute cut offes by inverting normal distribution\n",
    "    return(CutOffs)\n",
    "\n",
    "def get_cholesky_decomposition(rho, n):\n",
    "    # simulate jointly normals with sigma as vcov matrix\n",
    "    # use cholesky decomposition\n",
    "\n",
    "    sigma = get_correlation_matrix(rho, n)\n",
    "    c = cholesky(sigma)\n",
    "\n",
    "    return(c)\n",
    "\n",
    "def get_cut_ratings(transition_matrix, index_rating):\n",
    "    \n",
    "    # idx = position_data[\"RatingID\"]\n",
    "    cutOffs = get_cutoffs_rating(transition_matrix)\n",
    "    # cut off matrix for each bond based on their ratings\n",
    "    cut = np.matrix(cutOffs[:,index_rating]).T\n",
    "\n",
    "    return(cut)\n",
    "\n",
    "def get_credit_spreads(transition_matrix, LGD):\n",
    "    # credit spread implied by transmat\n",
    "    PD_t = transition_matrix[:,-1] # default probability at t\n",
    "    credit_spread = -np.log(1-LGD*PD_t)/1\n",
    "    \n",
    "    return(credit_spread)\n",
    "\n",
    "def get_expected_value (r, position_data,  transition_matrix, t):\n",
    "    exposure = np.matrix(position_data[\"Exposure\"]).T\n",
    "    # print(exposure)\n",
    "    idx = position_data[\"RatingID\"]\n",
    "    # print(idx)\n",
    "    LGD = 0.45\n",
    "    credit_spread = get_credit_spreads(transition_matrix, LGD)\n",
    "    # print(credit_spread)\n",
    "    EV = np.multiply(exposure, np.exp(-(r+credit_spread[idx])*t))\n",
    "\n",
    "    return(EV)\n",
    "\n",
    "def get_states (transition_matrix, position_data, r, t):\n",
    "    # bond state variable for security Value\n",
    "    LGD = 0.45\n",
    "    recover = 0.55\n",
    "    credit_spread = get_credit_spreads(transition_matrix, LGD)\n",
    "    cp = np.tile(credit_spread.T,[position_data[\"InstrumentID\"].nunique(),1])\n",
    "    # print(cp)\n",
    "    exposure = np.matrix(position_data[\"Exposure\"]).T\n",
    "    # print(exposure)\n",
    "    state = np.multiply(exposure,np.exp(-(r+cp)*t))\n",
    "    # print(state)\n",
    "    state = np.append(state,np.multiply(exposure,recover),axis=1) #last column is default case\n",
    "    # print(state)\n",
    "    states = np.fliplr(state) # keep in same order as credit cutoff\n",
    "    # print(states)\n",
    "\n",
    "    return(states)\n",
    "\n",
    "def mc_calculation(rho, n_issuer, n_simulation, transition_matrix, position_data, r, t):\n",
    "    # c = get_cholesky_distribution(rho, n_issuer)\n",
    "    correlation = get_correlation(mergedData)\n",
    "    cutOffs = get_cutoffs_rating(transition_matrix)\n",
    "    states = get_states (transition_matrix, position_data, r, t)\n",
    "    EV = get_expected_value (r, position_data,  transition_matrix, t)\n",
    "    n_positions = position_data[\"InstrumentID\"].nunique()\n",
    "    Loss = np.zeros((n_simulation,n_positions))\n",
    "    # np.random.seed(1)\n",
    "\n",
    "    for i in range(0,n_simulation):\n",
    "        YY = norm.ppf(np.random.rand())\n",
    "        # rr=c*YY.T\n",
    "        # rr = YY*rho\n",
    "        for j in range (0,n_positions):\n",
    "            rho = correlation[position_data.loc[j,'IssuerName']]\n",
    "            print(rho)\n",
    "            rr = YY*rho\n",
    "            YY_ido = norm.ppf(np.random.rand())\n",
    "            #corr_idio=np.sqrt((1-(c*c)))\n",
    "            rr_idio=np.sqrt(1-(rho**2))*YY_ido\n",
    "            # print(rr_idio)\n",
    "            rr_all=rr+rr_idio\n",
    "            # print(rr_all)\n",
    "            rating = np.array(rr_all<np.matrix(cutOffs[:,position_data.loc[j,\"RatingID\"]]).T)\n",
    "            rate_idx = len(rating) - np.sum(rating,0)\n",
    "            # print(rate_idx)\n",
    "            col_idx = rate_idx\n",
    "            V_t = states[j,col_idx] # retrieve the corresponding state value of the exposure\n",
    "            Loss_t = V_t-EV.item(j)\n",
    "            # print(Loss_t)\n",
    "            Loss[i,j] = Loss_t\n",
    "            # print(Loss)\n",
    "\n",
    "    # Portfolio_MC_Loss = np.sum(Loss,1)\n",
    "    return(Loss)\n",
    "\n",
    "def get_Loss_distribution (rho, n_issuer, n_simulation, transition_matrix, position_data, r, t):\n",
    "    Loss = mc_calculation(rho, n_issuer, n_simulation, transition_matrix, position_data, r, t)\n",
    "    Portfolio_MC_Loss = np.sum(Loss,1)\n",
    "\n",
    "    return(Portfolio_MC_Loss)\n",
    "\n",
    "def get_portfolio_VaR(rho, n_issuer, n_simulation, transition_matrix, position_data, r, t, confidencelevel):\n",
    "    loss_Distribution = get_Loss_distribution(rho, n_issuer, n_simulation, transition_matrix, position_data, r, t)\n",
    "    Port_Var = -1*np.percentile(loss_Distribution,confidencelevel)\n",
    "\n",
    "    return(Port_Var)\n",
    "\n",
    "def get_portfolio_ES(rho, n_issuer, n_simulation, transition_matrix, position_data, r, t, confidencelevel):\n",
    "    loss_Distribution = get_Loss_distribution(rho, n_issuer, n_simulation, transition_matrix, position_data, r, t)\n",
    "    portVar = get_portfolio_VaR(rho, n_issuer, n_simulation, transition_matrix, position_data, r, t, confidencelevel)\n",
    "\n",
    "    expectedShortfall = -1*np.mean(loss_Distribution[loss_Distribution<-1*portVar])\n",
    "\n",
    "    return(expectedShortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = get_portfolio_VaR(0.2, n_issuer, 5000, TransMat, positions_adj, r, t, 1)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8657731142064324\n",
      "0.8657731142064324\n",
      "0.6131327036957176\n",
      "0.6131327036957176\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.8657731142064324\n",
      "0.8657731142064324\n",
      "0.6131327036957176\n",
      "0.6131327036957176\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.8657731142064324\n",
      "0.8657731142064324\n",
      "0.6131327036957176\n",
      "0.6131327036957176\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.8657731142064324\n",
      "0.8657731142064324\n",
      "0.6131327036957176\n",
      "0.6131327036957176\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.8657731142064324\n",
      "0.8657731142064324\n",
      "0.6131327036957176\n",
      "0.6131327036957176\n",
      "0.50847337287472\n",
      "0.50847337287472\n",
      "0.50847337287472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -19696.5,       0. ,       0. , -154615.5,       0. ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = get_Loss_distribution(0.2, 3, 5, TransMat, mergePositionsIssuer(positions,issuer), r, t)\n",
    "tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = get_portfolio_ES(0.2, n_issuer, 2000, TransMat, positions_adj, r, t, 1)\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossDistribution = mc_calculation(0.2, n_issuer, 20000, TransMat, positions_adj, r, t)\n",
    "test_df = pd.DataFrame(lossDistribution)\n",
    "Port_Var = -1*np.percentile(lossDistribution,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.rename(columns={0: \"Value\"})\n",
    "test_df.groupby([\"Value\"]).size().reset_index(name='Count').sort_values(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(TransMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6adee53c13be7cf8582dc470917a193e541c9e29837d59b0c484fc99790beedb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
