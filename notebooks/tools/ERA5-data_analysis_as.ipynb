{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook to analyze wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product type:Reanalysis\n",
    "\n",
    "Variable: 100m u-component of wind, 100m v-component of wind, 10m u-component of wind, 10m v-component of wind\n",
    "\n",
    "Year: 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023\n",
    "\n",
    "Month: January, February, March, April, May, June, July, August, September, October, November, December\n",
    "\n",
    "Day: 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31\n",
    "\n",
    "Time: 00:00, 01:00, 02:00, 03:00, 04:00, 05:00, 06:00, 07:00, 08:00, 09:00, 10:00, 11:00, 12:00, 13:00, 14:00, 15:00, 16:00, 17:00, 18:00, 19:00, 20:00, 21:00, 22:00, 23:00\n",
    "\n",
    "Sub-region extraction: North 55째, West 6째, South 47째, East 15째\n",
    "\n",
    "Format: NetCDF (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ERA5/dataset_2012-2023.nc')\n",
    "#f = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ERA5/dataset_2012-2023_925hPa.nc')\n",
    "\n",
    "#f = xr.concat([f4, f3, f2, f1], dim='time')\n",
    "#f.to_netcdf('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ERA5/dataset_2012-2023.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = f.variables['longitude'][:]  # longitude\n",
    "lats = f.variables['latitude'][:]  # latitude\n",
    "u100 = f.variables['u100'][:,:,:,0] # u-wind at 100m height\n",
    "v100 = f.variables['v100'][:,:,:,0]  # v-wind at 100m height\n",
    "u10 = f.variables['u10'][:,:,:,0]  # u-wind at 10m height\n",
    "v10 = f.variables['v10'][:,:,:,0]  # v-wind at 10m height\n",
    "time = f.variables['time'][:]\n",
    "\n",
    "ws100 = np.array(np.sqrt(u100*u100+v100*v100))\n",
    "ws10 = np.array(np.sqrt(u10*u10+v10*v10))\n",
    "\n",
    "##u_tmp = u[~np.isnan(u[:,1,0,0,0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Basemap(llcrnrlon=5,llcrnrlat=47,urcrnrlon=15,urcrnrlat=55,\n",
    "             resolution='i', projection='tmerc', lat_0 = 80, lon_0 = 20)\n",
    "\n",
    "lon, lat = np.meshgrid(lons, lats)\n",
    "xi, yi = m(lon, lat)\n",
    "\n",
    "#define two locations\n",
    "loc1 = 15\n",
    "loc2 = 25\n",
    "#loc3 = 1\n",
    "#loc4 = 16\n",
    "\n",
    "x1,y1 = m(lon[loc1,loc1], lat[loc1,loc1])\n",
    "x2,y2 = m(lon[loc2,loc2], lat[loc2,loc2])\n",
    "#x3,y3 = m(lon[loc3,loc3], lat[loc3,loc3])\n",
    "#x4,y4 = m(lon[loc4,loc4], lat[loc4,loc4])\n",
    "\n",
    "cs = m.pcolor(xi,yi,np.squeeze(ws100[10,:,:]))\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary()\n",
    "m.drawcountries()\n",
    "cbar = m.colorbar(cs, location='right', pad=\"10%\")\n",
    "tt = np.array(time[10], dtype='datetime64[m]') #10 & 4378\n",
    "plt.title('wind speed in m/s at 100m height; time = '+str(tt))\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "#plt.plot(xi[lon1,lon1], yi[lat1,lat1],'ro')\n",
    "#plt.plot(x1, y1,'ro')\n",
    "#plt.plot(x2, y2,'ro')\n",
    "#plt.plot(x3, y3,'ro')\n",
    "#plt.plot(x4, y4,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1=1\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(time[:],ws100[:,loc1,loc1])\n",
    "sel_lon = np.array(lons[loc1])\n",
    "sel_lat = np.array(lats[loc1])\n",
    "plt.title('Longitude = '+str(sel_lon)+'; Latitude = '+str(sel_lat))\n",
    "plt.ylabel('wind speed in m/s')\n",
    "plt.xlabel('time')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(time[:],ws100[:,loc2,loc2],)\n",
    "sel_lon = np.array(lons[loc2])\n",
    "sel_lat = np.array(lats[loc2])\n",
    "plt.title('Longitude = '+str(sel_lon)+'; Latitude = '+str(sel_lat))\n",
    "plt.ylabel('wind speed in m/s')\n",
    "plt.xlabel('time')\n",
    "#plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deseasonalization, Principal Component Analysis and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit \n",
    "\n",
    "def time_as_year_fraction(time):\n",
    "    first_date=time[:][0].values \n",
    "    diff_in_sec = ((time[:][:].values-first_date)) / np.timedelta64(1, 's')\n",
    "    time_frac = diff_in_sec / (365*24*60*60) #days, hours, minutes, seconds\n",
    "    return time_frac\n",
    "    #year = first_date.astype('datetime64[Y]').astype(int) + 1970\n",
    "    #month = first_date.astype('datetime64[M]').astype(int) % 12 + 1\n",
    "    #day = (first_date.astype('datetime64[D]') - first_date.astype('datetime64[M]')).astype(int) + 1\n",
    "\n",
    "def deseasonalize_data(time, data, loc1, loc2=None, plot=False): #time=time_frac, data=ws100\n",
    "\n",
    "    def sin_func(x,a,b,c,d):\n",
    "        return a * np.sin(b * x + c) + d\n",
    "    \n",
    "    def monthly_func(x, *args):\n",
    "        a = (x*365/31) #month\n",
    "        b = np.full(a.shape, args[11])\n",
    "        for i in range(11, 0, -1):\n",
    "            b[a<i] = args[i-1]\n",
    "        return b\n",
    "\n",
    "    if loc2 is None:\n",
    "        loc2 = loc1\n",
    "    \n",
    "    nan_idx = np.argwhere(~np.isnan(data[:,loc1,loc2])).T[0] #index of all not nan values\n",
    "    xdata = time[nan_idx]\n",
    "    ydata = data[nan_idx, loc1, loc2]\n",
    "    time_shifted = np.copy(xdata) % 1\n",
    "\n",
    "    popt, _ = curve_fit(monthly_func, time_shifted, ydata, p0=[1]*12)#, bounds=([-1., -1., -10., 0.], [3., 3., 10., 10.,])) #pcov, info, msg, ier: p0=[1,1,1,1], full_output=True\n",
    "    ydata_deseasonalized = ydata - monthly_func(time_shifted, *popt)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(xdata, ydata, label='data')\n",
    "        plt.plot(xdata, monthly_func(time_shifted, *popt), label='monthly_avg')#, label='fit: a=%5.3f, b=%5.3f, c=%5.3f, d=%5.3f' % tuple(popt))\n",
    "        plt.plot(xdata, ydata_deseasonalized, label='deseasonalized data', alpha=0.7)\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('wind speed in m/s')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return ydata_deseasonalized, popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = 15\n",
    "loc2 = 25\n",
    "locs = [1,15,16,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frac = time_as_year_fraction(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deseasonalization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot at different locations\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "a = 0\n",
    "for i,k in enumerate(locs):\n",
    "    for j,l in enumerate(locs):\n",
    "        ws100_loc1 = ws100[:,k,k]\n",
    "        ws100_loc2 = ws100[:,l,l]\n",
    "        a += 1\n",
    "        ax1 = fig.add_subplot(len(locs), len(locs),a)\n",
    "        ax1.title.set_text('loc: '+str(k)+', '+str(l))\n",
    "        plt.plot(ws100_loc1, ws100_loc2, '.', alpha=0.1)\n",
    "        plt.tight_layout()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws100_deseasonalized, monthly_params = deseasonalize_data(time=time_frac, data=ws100, loc1=loc1, plot=True)\n",
    "#print(monthly_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(18,4))\n",
    "for loc1 in locs:\n",
    "    df = pd.DataFrame({'time': time, 'value': ws100[:,loc1,loc1], 'mean': ws100[:,loc1,loc1], 'mean_error': ws100[:,loc1,loc1], 'var': ws100[:,loc1,loc1]})\n",
    "    dfmonth = df['time'].dt.month\n",
    "    dfyear = df['time'].dt.year\n",
    "    for i in range(1,13):\n",
    "        mean = (df[dfmonth == i]['value'].mean())\n",
    "        var = (df[dfmonth == i]['value'].std())\n",
    "        df.loc[dfmonth == i,'mean'] = mean\n",
    "        df.loc[dfmonth == i,'mean_error'] -= mean\n",
    "        df.loc[dfmonth == i,'var'] = var\n",
    "    time_plot = df[dfyear==2022]['time']\n",
    "    axs[0].plot(time_plot, df[dfyear==2022]['var'], label='location: '+str(loc1))\n",
    "    axs[0].legend(loc=\"upper right\")\n",
    "    axs[0].set_title('Std. dev.')\n",
    "    axs[1].plot(time_plot, df[dfyear==2022]['mean'])\n",
    "    axs[1].set_title('Mean')\n",
    "    axs[2].plot(time_plot, df[dfyear==2022]['var']/df[dfyear==2022]['mean'])\n",
    "    axs[2].set_title('Std. dev. / Mean')\n",
    "    #plt.plot(df['time'], df['var'], label='location: '+str(loc1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#last loc only\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(df[dfmonth==1]['mean_error'], bins=100, alpha=0.5, density=True, label='January')\n",
    "plt.hist(df[dfmonth==8]['mean_error'], bins=100, alpha=0.5, density=True, label='August')\n",
    "plt.legend()\n",
    "plt.title('Histogram of mean error in specific month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_window = [1,12,24]\n",
    "for i in (roll_window):\n",
    "    df = pd.DataFrame({'data': ws100[:,loc1,loc1]})\n",
    "    df['moving_avg'] = df['data'].shift(-1).rolling(i).mean() \n",
    "    df['data_w/o_moving_avg'] = df['data']-df['moving_avg']\n",
    "    df.plot(figsize=(20,5));\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.hist(df['data_w/o_moving_avg'], density=True, bins=50)\n",
    "    plt.title('Histogram of wind speed over time w/o moving average')\n",
    "    plt.show()\n",
    "\n",
    "    from statsmodels.graphics.tsaplots import plot_acf\n",
    "    nan_idx = np.argwhere(~np.isnan(df['data_w/o_moving_avg'])).T[0] #11:-1545\n",
    "    plot_acf(df['data_w/o_moving_avg'][nan_idx]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_window = [1,12,24]\n",
    "for i in (roll_window):\n",
    "    fig, axs = plt.subplots(1,3, figsize=(15,4))\n",
    "\n",
    "    for loc1 in locs:\n",
    "        nan_idx = np.argwhere(~np.isnan(ws100[:,loc1,loc1])).T[0]\n",
    "        df = pd.DataFrame({'data': ws100[nan_idx,loc1,loc1]})\n",
    "        df['moving_avg'] = df['data'].shift(-1).rolling(i).mean() #6,12,24h\n",
    "        df['data_w/o_moving_avg'] = df['data']-df['moving_avg']\n",
    "        \n",
    "        df = pd.DataFrame({'time': time[nan_idx], 'value': df['data_w/o_moving_avg'], 'mean': df['data_w/o_moving_avg'], 'mean_error': df['data_w/o_moving_avg'], 'var': df['data_w/o_moving_avg']})\n",
    "        dfmonth = df['time'].dt.month\n",
    "        dfyear = df['time'].dt.year\n",
    "        for i in range(1,13):\n",
    "            mean = (df[dfmonth == i]['value'].mean())\n",
    "            var = (df[dfmonth == i]['value'].std())\n",
    "            df.loc[dfmonth == i,'mean'] = mean\n",
    "            df.loc[dfmonth == i,'mean_error'] -= mean\n",
    "            df.loc[dfmonth == i,'var'] = var\n",
    "        time_plot = df[dfyear==2022]['time']\n",
    "        axs[0].plot(time_plot, df[dfyear==2022]['var'], label='location: '+str(loc1))\n",
    "        axs[0].legend()\n",
    "        axs[0].set_title('Std. dev.')\n",
    "        axs[1].plot(time_plot, df[dfyear==2022]['mean'])\n",
    "        axs[1].set_title('Mean')\n",
    "        axs[2].hist(df[dfmonth==1]['mean_error'], bins=100, alpha=0.5, density=True, label='January, loc: '+str(loc1))\n",
    "        axs[2].hist(df[dfmonth==8]['mean_error'], bins=100, alpha=0.5, density=True, label='August, loc: '+str(loc1))\n",
    "        axs[2].legend()\n",
    "        axs[2].set_title('Mean error')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "a = 0\n",
    "for i,k in enumerate(locs):\n",
    "    for j,l in enumerate(locs):\n",
    "        df_loc1 = pd.DataFrame({'data': ws100[:,k,k]})\n",
    "        df_loc2 = pd.DataFrame({'data': ws100[:,l,l]})\n",
    "        df_loc1['moving_avg'] = df_loc1['data'].shift(1).rolling(window=24).mean() \n",
    "        df_loc1['data_w/o_moving_avg'] = df_loc1['data']-df_loc1['moving_avg']\n",
    "        df_loc2['moving_avg'] = df_loc2['data'].shift(1).rolling(window=24).mean() \n",
    "        df_loc2['data_w/o_moving_avg'] = df_loc2['data']-df_loc2['moving_avg']\n",
    "        a += 1\n",
    "        ax1 = fig.add_subplot(len(locs), len(locs),a)\n",
    "        ax1.title.set_text('loc: '+str(k)+', '+str(l))\n",
    "        plt.plot(df_loc1['data_w/o_moving_avg'], df_loc2['data_w/o_moving_avg'], '.', alpha=0.1)\n",
    "        plt.tight_layout()\n",
    "plt.title('Scatter Plot at different locations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by hours\n",
    "if False:\n",
    "    ws100_deseasonalized, monthly_params = deseasonalize_data(time=time_frac, data=ws100, loc1=loc1)\n",
    "    time_nan = time[np.argwhere(~np.isnan(ws100[:,loc1,loc1])).T[0] ]\n",
    "\n",
    "    df = pd.DataFrame({'time': time_nan, 'value': ws100_deseasonalized, 'mean': ws100_deseasonalized, 'mean_error': ws100_deseasonalized, 'var': ws100_deseasonalized})\n",
    "    df2 = pd.DataFrame({'time': time, 'value': ws100[:,loc1,loc1], 'mean': ws100[:,loc1,loc1], 'mean_error': ws100[:,loc1,loc1], 'var': ws100[:,loc1,loc1]})\n",
    "\n",
    "    dfhour = df['time'].dt.hour\n",
    "    df2hour = df2['time'].dt.hour\n",
    "\n",
    "    for i in range(np.unique(dfhour)[-1]+1):\n",
    "        mean = (df[dfhour == i]['value'].mean())\n",
    "        mean2 = (df2[df2hour == i]['value'].mean())\n",
    "        var = (df[dfhour == i]['value'].std())\n",
    "        var2 = (df2[df2hour == i]['value'].std())\n",
    "        df.loc[dfhour == i,'mean'] = mean\n",
    "        df.loc[dfhour == i,'mean_error'] -= mean\n",
    "        df.loc[dfhour == i,'var'] = var\n",
    "        df2.loc[df2hour == i,'mean'] = mean2\n",
    "        df2.loc[df2hour == i,'mean_error'] -= mean2\n",
    "        df2.loc[df2hour == i,'var'] = var2\n",
    "\n",
    "    sel_day = df.loc[(df['time']>='1/1/22') & (df['time']<'1/2/22')]\n",
    "    sel_day2 = df2.loc[(df2['time']>='1/1/22') & (df2['time']<'1/2/22')]\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(sel_day['time'].dt.hour, sel_day['var'], 'o-', label='std_deseasonalized')\n",
    "    plt.plot(sel_day2['time'].dt.hour, sel_day2['var'], 'x-', label='std')\n",
    "    plt.xlabel('time')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    fig,ax1 = plt.subplots(figsize=(12,4))\n",
    "    ax1.plot(sel_day['time'].dt.hour, sel_day['mean'], 'o-', color='tab:blue', label='mean_deseasonalized')\n",
    "    ax1.set_ylabel('mean_deseasonalized', color = 'tab:blue') \n",
    "    ax1.set_xlabel('time')\n",
    "    ax2 = ax1.twinx() \n",
    "    ax2.plot(sel_day2['time'].dt.hour, sel_day2['mean'], 'x-', color='tab:orange', label='mean')\n",
    "    ax2.set_ylabel('mean', color = 'tab:orange') \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(df[dfhour==4]['mean_error'], bins=100, alpha=0.5, density=True, label='4 o\\'clock')\n",
    "    plt.hist(df[dfhour==9]['mean_error'], bins=100, alpha=0.5, density=True, label='9 o\\'clock')\n",
    "    plt.hist(df[dfhour==10]['mean_error'], bins=100, alpha=0.5, density=True, label='10 o\\'clock')\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of mean error at specific hour')\n",
    "    plt.show()\n",
    "\n",
    "# day/night\n",
    "if False:\n",
    "    ws100_deseasonalized, monthly_params = deseasonalize_data(time=time_frac, data=ws100, loc1=loc1)\n",
    "    time_nan = time[np.argwhere(~np.isnan(ws100[:,loc1,loc1])).T[0] ]\n",
    "\n",
    "    df = pd.DataFrame({'time': time_nan, 'value': ws100_deseasonalized, 'mean': ws100_deseasonalized, 'mean_error': ws100_deseasonalized, 'var': ws100_deseasonalized})\n",
    "\n",
    "    dfhour10_16 = df[(df['time'].dt.hour >= 10) & (df['time'].dt.hour <= 16)]['time'].dt.hour\n",
    "\n",
    "    df_1016_idx = df.loc[df.index.isin(dfhour10_16.index)] #df.iloc[dfhour10_16.index]\n",
    "    df_else_idx = df.loc[~df.index.isin(dfhour10_16.index)]\n",
    "\n",
    "    #for 10-14h & rest\n",
    "    mean = df_1016_idx['value'].mean()\n",
    "    mean2 = df_else_idx['value'].mean()\n",
    "    var = df_1016_idx['value'].std()\n",
    "    var2 = df_else_idx['value'].std()\n",
    "    df.loc[dfhour10_16.index,'mean'] = mean\n",
    "    df.loc[~df.index.isin(dfhour10_16.index),'mean'] = mean2\n",
    "    df.loc[dfhour10_16.index,'mean_error'] -= mean\n",
    "    df.loc[~df.index.isin(dfhour10_16.index),'mean_error'] -= mean2\n",
    "    df.loc[dfhour10_16.index,'var'] = var\n",
    "    df.loc[~df.index.isin(dfhour10_16.index),'var'] = var2\n",
    "\n",
    "    fig,ax1 = plt.subplots(figsize=(12,4))\n",
    "    sel_day = df.loc[(df['time']>='1/1/22') & (df['time']<'1/2/22')]\n",
    "    ax1.plot(sel_day['time'].dt.hour, sel_day['mean'], 'o-', color='tab:blue', label='mean')\n",
    "    ax1.set_ylabel('mean', color = 'tab:blue') \n",
    "    ax1.set_xlabel('time')\n",
    "    ax2 = ax1.twinx() \n",
    "    ax2.plot(sel_day['time'].dt.hour, sel_day['var'], 'x-', color='tab:orange', label='var')\n",
    "    ax2.set_ylabel('var', color = 'tab:orange') \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(df.loc[dfhour10_16.index,'mean_error'], bins=100, alpha=0.5, density=True, label='10-16h')\n",
    "    plt.hist(df.loc[~df.index.isin(dfhour10_16.index),'mean_error'], bins=100, alpha=0.5, density=True, label='16-10h')\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of mean error at specific times')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "nan_idx = np.argwhere(~np.isnan(ws100[:,0,0])).T[0] #11:-1545\n",
    "time_nan = time[nan_idx]\n",
    "Y = ws100[nan_idx,:,:]\n",
    "X = Y.reshape(Y.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40)\n",
    "X_red = pca.fit_transform(X) #shape (time, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "#plt.scatter(X_red[:, 0], X_red[:, 1], alpha=0.3, label=\"samples\")\n",
    "#plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.linspace(1,pca.n_components_,pca.n_components_), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#components over time\n",
    "for loc0 in range(X_red.shape[1]):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(time_nan[:500],X_red[:500,loc0], '.')\n",
    "    plt.ylabel('wind speed in m/s')\n",
    "    plt.xlabel('time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basis functions on map\n",
    "components_loc = pca.components_.reshape(pca.n_components_, ws100.shape[1], ws100.shape[2]) #(n_components, 1221)->(n_components, 33, 37)\n",
    "\n",
    "lon, lat = np.meshgrid(lons, lats)\n",
    "\n",
    "for i in range(pca.n_components_):\n",
    "    m = Basemap(llcrnrlon=5,llcrnrlat=47,urcrnrlon=15,urcrnrlat=55,\n",
    "             resolution='i', projection='tmerc', lat_0 = 80, lon_0 = 20)\n",
    "    xi, yi = m(lon, lat)\n",
    "    cs = m.pcolor(xi,yi,np.squeeze(components_loc[i])) #ws100[0,:,:]\n",
    "    m.drawcoastlines()\n",
    "    m.drawmapboundary()\n",
    "    m.drawcountries()\n",
    "    cbar = m.colorbar(cs, location='right', pad=\"10%\")\n",
    "    tt = np.array(time[0], dtype='datetime64[m]') #10 & 4378\n",
    "    plt.title('wind speed in m/s at 100m height; time = '+str(tt))\n",
    "    plt.xlabel('longitude')\n",
    "    plt.ylabel('latitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error plot for specific point\n",
    "for loc0 in range(0,30,5):\n",
    "    true_val = ws100[nan_idx,loc0,loc0]\n",
    "    approx_val = pca.inverse_transform(X_red).reshape(Y.shape)[:,loc0,loc0]\n",
    "    error = (approx_val - true_val)[0:240]\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(error)\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error plot for specific time\n",
    "time_point = 10\n",
    "for time_point in range(0,100,20):\n",
    "    true_val = ws100[time_point,:,:]\n",
    "    approx_val = pca.inverse_transform(X_red).reshape(Y.shape)[time_point,:,:] #np.matmul(X_20, pca.components_)\n",
    "    error = approx_val - true_val\n",
    "\n",
    "    lon, lat = np.meshgrid(lons, lats)\n",
    "    xi, yi = m(lon, lat)\n",
    "\n",
    "    m = Basemap(llcrnrlon=5,llcrnrlat=47,urcrnrlon=15,urcrnrlat=55,\n",
    "                resolution='i', projection='tmerc', lat_0 = 80, lon_0 = 20)\n",
    "    cs = m.pcolor(xi, yi, error, cmap='coolwarm')\n",
    "    m.drawcoastlines()\n",
    "    m.drawmapboundary()\n",
    "    m.drawcountries()\n",
    "    cbar = m.colorbar(cs, location='right', pad=\"10%\")\n",
    "    tt = np.array(time[time_point], dtype='datetime64[m]') #10 & 4378\n",
    "    plt.title('wind speed in m/s at 100m height; time = '+str(tt))\n",
    "    plt.xlabel('longitude')\n",
    "    plt.ylabel('latitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "#nan_idx = np.argwhere(~np.isnan(ws100[:,0,0])).T[0] #11:-1545\n",
    "true_val = ws100[nan_idx,:,:].reshape(X.shape) # [time_point,loc0,loc0]\n",
    "approx_val = pca.inverse_transform(X_red)#.reshape(Y.shape)\n",
    "error = approx_val - true_val\n",
    "\n",
    "for i in[0]: # location\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(error[:,i], true_val[:,i], '.', alpha=0.02) #scatter plot: error vs. true value\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(error[:,i], error[:,i+1], '.', alpha=0.2) #scatter plot: error at two locations\n",
    "    plt.show()\n",
    "\n",
    "    #difference to last hour / second diff (diff of diff)\n",
    "    df = pd.DataFrame(error)\n",
    "    df1 = pd.DataFrame({'data': df.loc[:,i]})\n",
    "    df1['data_diff'] = df1['data'] - df1['data'].shift(-1).rolling(1).mean()\n",
    "    df1['data_sec_diff'] = df1['data_diff'] - df1['data_diff'].shift(-1).rolling(1).mean()\n",
    "\n",
    "    #autocorrelation\n",
    "    plot_acf(df1['data']); #column, time: 102264 \n",
    "    plot_acf(df1['data_diff'][:-1])\n",
    "    plot_acf(df1['data_sec_diff'][:-2])\n",
    "\n",
    "    #histogram of error\n",
    "    plt.figure()\n",
    "    plt.hist(error[:,i], bins=50, density=True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(df1['data_diff'], bins=50, density=True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(df1['data_sec_diff'], bins=50, density=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation\n",
    "corr_matrix = np.corrcoef(X_red.T)\n",
    "\n",
    "plt.imshow(corr_matrix, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error in Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from scipy.stats import norm\n",
    "\n",
    "wind_speed = np.linspace(0,25,51)\n",
    "performance = np.array([0, 0, 0, 0, 3, 10, 25, 49, 82, 123, 174, 240, 321, 418, 532, 664, 815, 988, 1180, 1384, 1580, 1749, 1890, 2005, 2100, 2180, 2250, 2311, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350])\n",
    "\n",
    "interp_perf = interpolate.UnivariateSpline(wind_speed, performance, s=0)\n",
    "def convert_wind_to_performance(ws):\n",
    "    return interp_perf(ws)\n",
    "\n",
    "#xnew = np.arange(0,25,1)\n",
    "#plt.plot(wind_speed,performance,'x',xnew,interp_perf(xnew))\n",
    "#convert_wind_to_performance(5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different n_components in pca \n",
    "\n",
    "location = 0\n",
    "for n_comp in [10,20,40,100]:\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    X_red = pca.fit_transform(X) #shape (time, n_components)\n",
    "\n",
    "    true_val_performance = convert_wind_to_performance(ws100[nan_idx,:,:].reshape(X.shape)) # [time_point,loc0,loc0]\n",
    "    approx_val_performance = convert_wind_to_performance(pca.inverse_transform(X_red))\n",
    "    error_performance = approx_val_performance - true_val_performance\n",
    "\n",
    "    if True:\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.plot(true_val_performance[:240,location], label='true')\n",
    "        plt.plot(approx_val_performance[:240,location], label='pred')\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('performance')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.plot(error_performance[:,location])\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('error')\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(error_performance[:,location], density=True, bins=100, alpha=0.6)\n",
    "        mu, std = norm.fit(error_performance[:,location])\n",
    "        xmin, xmax = plt.xlim()\n",
    "        x = np.linspace(xmin, xmax, 100)\n",
    "        p = norm.pdf(x, mu, std)\n",
    "        plt.plot(x, p, 'k', linewidth=2)\n",
    "        title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different locations in one pca\n",
    " \n",
    "pca = PCA(n_components=20)\n",
    "X_red = pca.fit_transform(X) #shape (time, n_components)\n",
    "\n",
    "true_val_performance = convert_wind_to_performance(ws100[nan_idx,:,:].reshape(X.shape)) # [time_point,loc0,loc0]\n",
    "approx_val_performance = convert_wind_to_performance(pca.inverse_transform(X_red))\n",
    "error_performance = approx_val_performance - true_val_performance\n",
    "\n",
    "for location in locs:\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(true_val_performance[:240,location], label='true')\n",
    "    plt.plot(approx_val_performance[:240,location], label='pred')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('performance')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(error_performance[:,location])\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(error_performance[:,location], density=True, bins=100, alpha=0.6)\n",
    "    mu, std = norm.fit(error_performance[:,location])\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, std)\n",
    "    plt.plot(x, p, 'k', linewidth=2)\n",
    "    title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximum error in coordinates\n",
    "\n",
    "max_in_coordinate = np.max(np.abs(error_performance), axis=0)\n",
    "#argmax_in_coordinate = np.argmax(error_performance, axis=0)\n",
    "plt.plot(max_in_coordinate)\n",
    "plt.show()\n",
    "\n",
    "#max_in_time = np.max(np.abs(error_performance), axis=1)\n",
    "#plt.plot(max_in_time)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between locations\n",
    "nan_idx = np.argwhere(~np.isnan(ws100[:,0,0])).T[0]\n",
    "ws100_deseasonalized = ws100[nan_idx,:,:]\n",
    "for loc1 in range(len(lats)):\n",
    "    for loc2 in range(len(lons)):\n",
    "        ws100_deseasonalized[:,loc1,loc2], _ = deseasonalize_data(time=time_frac, data=ws100, loc1=loc1, loc2=loc2, plot=False)\n",
    "all_places = ws100_deseasonalized.reshape(ws100_deseasonalized.shape[0], -1) #loc: :,::3,::3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(all_places.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corr_matrix, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Unsorted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_ = np.sqrt(2.0*(1.0-corr_matrix))\n",
    "\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=15, affinity='precomputed', linkage='complete')\n",
    "X_pred = agg_clustering.fit_predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_locs = X_pred.reshape(ws100_deseasonalized.shape[1],ws100_deseasonalized.shape[2])\n",
    "\n",
    "m = Basemap(llcrnrlon=5.6,llcrnrlat=46.7,urcrnrlon=16.5,urcrnrlat=55.1, resolution='i', projection='tmerc', lat_0 = 80, lon_0 = 10)\n",
    "lon, lat = np.meshgrid(lons, lats)\n",
    "xi, yi = m(lon, lat)\n",
    "cmap = plt.cm.get_cmap('hsv', np.unique(X_pred_locs)[-1]+1)\n",
    "cs = m.pcolor(xi, yi, X_pred_locs, cmap=cmap)\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary()\n",
    "m.drawcountries()\n",
    "plt.title('Clustering of wind speed in m/s at 100m height')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centres = np.empty((agg_clustering.n_clusters_), dtype=int)\n",
    "for i in range(agg_clustering.n_clusters_):\n",
    "    this_cluster = np.where(agg_clustering.labels_ == i)[0]\n",
    "    cluster_places = all_places[:,this_cluster]\n",
    "    cluster_cov = np.corrcoef(cluster_places.T)\n",
    "    cluster_X_ = np.sqrt(2.0*(1.0-cluster_cov))\n",
    "    row_sums = cluster_X_.sum(axis=1)\n",
    "    cluster_centre_local = np.argmin(row_sums)\n",
    "    cluster_centres[i] = this_cluster[cluster_centre_local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_locs = X_pred.reshape(ws100_deseasonalized.shape[1],ws100_deseasonalized.shape[2])\n",
    "\n",
    "m = Basemap(llcrnrlon=5.6,llcrnrlat=46.7,urcrnrlon=16.5,urcrnrlat=55.1, resolution='i', projection='tmerc', lat_0 = 80, lon_0 = 10)\n",
    "lon, lat = np.meshgrid(lons, lats)\n",
    "xi, yi = m(lon, lat)\n",
    "cmap = plt.cm.get_cmap('hsv', np.unique(X_pred_locs)[-1]+1)\n",
    "cs = m.pcolor(xi, yi, X_pred_locs, cmap=cmap)\n",
    "\n",
    "x_c, y_c = m(lon.flatten()[cluster_centres], lat.flatten()[cluster_centres])\n",
    "plt.plot(x_c, y_c,'ro')\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary()\n",
    "m.drawcountries()\n",
    "plt.title('Clustering of wind speed in m/s at 100m height')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_serial_matrix(dist_mat, mat, model):\n",
    "    '''\n",
    "        input:\n",
    "            - dist_mat is a distance matrix\n",
    "            - method = [\"ward\",\"single\",\"average\",\"complete\"]\n",
    "        output:\n",
    "            - seriated_dist is the input dist_mat,\n",
    "              but with re-ordered rows and columns\n",
    "              according to the seriation, i.e. the\n",
    "              order implied by the hierarchical tree\n",
    "            - res_order is the order implied by\n",
    "              the hierarhical tree\n",
    "            - res_linkage is the hierarhical tree (dendrogram)\n",
    "        \n",
    "        compute_serial_matrix transforms a distance matrix into \n",
    "        a sorted distance matrix according to the order implied \n",
    "        by the hierarchical tree (dendrogram)\n",
    "    '''\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    def seriation(Z,N,cur_index):\n",
    "        '''\n",
    "            input:\n",
    "                - Z is a hierarchical tree (dendrogram)\n",
    "                - N is the number of points given to the clustering process\n",
    "                - cur_index is the position in the tree for the recursive traversal\n",
    "            output:\n",
    "                - order implied by the hierarchical tree Z\n",
    "\n",
    "            seriation computes the order implied by a hierarchical tree (dendrogram)\n",
    "        '''\n",
    "        if cur_index < N:\n",
    "            return [cur_index]\n",
    "        else:\n",
    "            left = int(Z[cur_index-N,0])\n",
    "            right = int(Z[cur_index-N,1])\n",
    "            return (seriation(Z,N,left) + seriation(Z,N,right))\n",
    "    \n",
    "    def create_linkage_matrix(X, model, mode='l2'):\n",
    "        distances = []\n",
    "        weights = []\n",
    "        children=model.children_\n",
    "        dims = (X.shape[1],1)\n",
    "        distCache = {}\n",
    "        weightCache = {}\n",
    "        for childs in children:\n",
    "            c1 = X[childs[0]].reshape(dims)\n",
    "            c2 = X[childs[1]].reshape(dims)\n",
    "            c1Dist = 0\n",
    "            c1W = 1\n",
    "            c2Dist = 0\n",
    "            c2W = 1\n",
    "            if childs[0] in distCache.keys():\n",
    "                c1Dist = distCache[childs[0]]\n",
    "                c1W = weightCache[childs[0]]\n",
    "            if childs[1] in distCache.keys():\n",
    "                c2Dist = distCache[childs[1]]\n",
    "                c2W = weightCache[childs[1]]\n",
    "            d = np.linalg.norm(c1-c2)\n",
    "            cc = ((c1W*c1)+(c2W*c2))/(c1W+c2W)\n",
    "\n",
    "            X = np.vstack((X,cc.T))\n",
    "\n",
    "            newChild_id = X.shape[0]-1\n",
    "\n",
    "            # How to deal with a higher level cluster merge with lower distance:\n",
    "            if mode=='l2':  # Increase the higher level cluster size suing an l2 norm\n",
    "                added_dist = (c1Dist**2+c2Dist**2)**0.5 \n",
    "                dNew = (d**2 + added_dist**2)**0.5\n",
    "            elif mode == 'max':  # If the previrous clusters had higher distance, use that one\n",
    "                dNew = max(d,c1Dist,c2Dist)\n",
    "            elif mode == 'actual':  # Plot the actual distance.\n",
    "                dNew = d\n",
    "\n",
    "            wNew = (c1W + c2W)\n",
    "            distCache[newChild_id] = dNew\n",
    "            weightCache[newChild_id] = wNew\n",
    "\n",
    "            distances.append(dNew)\n",
    "            weights.append(wNew)\n",
    "        linkage_matrix = np.column_stack([model.children_, distances, weights]).astype(float)\n",
    "        return linkage_matrix\n",
    "    N = len(dist_mat)\n",
    "    #flat_dist_mat = squareform(dist_mat)\n",
    "    #res_linkage = linkage(flat_dist_mat, method=method,preserve_input=True)\n",
    "    res_linkage = create_linkage_matrix(dist_mat,model)\n",
    "    res_order = seriation(res_linkage, N, N + N-2)\n",
    "    #seriated_dist = np.zeros((N,N))\n",
    "    a,b = np.triu_indices(N,k=1)\n",
    "    result = np.copy(mat)\n",
    "    result[a,b] = result[ [res_order[i] for i in a], [res_order[j] for j in b]]\n",
    "    result[b,a] = result[a,b]\n",
    "    \n",
    "    return result, res_order, res_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_corr, res_order, res_linkage = compute_serial_matrix(X_, corr_matrix, agg_clustering)\n",
    "plt.imshow(ordered_corr, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Sorted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.fft\n",
    "x = np.linspace(0,1,100)\n",
    "y = np.sin(2*np.pi*x) #sin(2pix) -> [0,1]\n",
    "y2 = np.sin(2*np.pi*x + 1) #sin(2pix+1) -> [0,1]\n",
    "zs = scipy.fft.fft(y)\n",
    "zs2 = scipy.fft.fft(y2)\n",
    "freq = scipy.fft.fftshift(scipy.fft.fftfreq(x.shape[-1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x[1:], zs[1:])\n",
    "plt.plot(x[1:], zs2[1:])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(freq, zs.real, freq, zs.imag)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x = np.linspace(0,1,100)\n",
    "y = np.sin(2*np.pi*x) #sin(2pix) -> [0,1]\n",
    "y2 = np.sin(2*np.pi*x + 1) #sin(2pix+1) -> [0,1]\n",
    "z = np.fft.fft(y)\n",
    "z2 = np.fft.fft(y2)\n",
    "freq = np.fft.fftfreq(x.shape[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x[2:-1], z[2:-1])\n",
    "plt.plot(x[2:-1], z2[2:-1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(freq, z.real, freq, z.imag)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind speed during the christmas season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = xr.open_dataset('/Users/angelina/Documents/eworld/dataset_era5_december2023.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = f.variables['longitude']  #len:1440 (values: 0-360)\n",
    "lats = f.variables['latitude']  #721 (90,-90)\n",
    "time = f.variables['time'] #744\n",
    "u = f.variables['u'][:,0,:,:]\n",
    "v = f.variables['v'][:,0,:,:]\n",
    "\n",
    "ws = np.array(np.sqrt(u*u+v*v))\n",
    "\n",
    "ger_lons = lons[24:61] #germany ~6-15\n",
    "ger_lats = lats[140:172] #germany ~55-47.25\n",
    "\n",
    "scai_lon = 5 #7.25 ~7.202800904147935\n",
    "scai_lat = 17 #50.75 ~50.749203582484625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Basemap(llcrnrlon=5.8,llcrnrlat=47,urcrnrlon=15.8,urcrnrlat=55,\n",
    "             resolution='i', projection='tmerc', lat_0 = 0, lon_0 = 10)\n",
    "\n",
    "time_set = 570 #66\n",
    "#tt = f['time'][time_set].dt.strftime(\"%Y-%m-%d %H:%Mh\").variable.values\n",
    "\n",
    "lon, lat = np.meshgrid(ger_lons, ger_lats)\n",
    "xi, yi = m(lon, lat)\n",
    "cs = m.pcolor(xi,yi,np.squeeze(ws[time_set,140:172,24:61]), vmin=0, vmax=30) \n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary()\n",
    "m.drawcountries()\n",
    "cbar = m.colorbar(cs, location='right', pad=\"10%\")\n",
    "plt.plot(xi[scai_lat, scai_lon], yi[scai_lat, scai_lon],'ro')\n",
    "plt.title('wind speed in m/s')\n",
    "#plt.xlabel('longitude')\n",
    "#plt.ylabel('latitude')\n",
    "plt.savefig('/Users/angelina/Documents/eworld/wind_speed_true.jpg', dpi=1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(time, ws[:,scai_lat,scai_lon]) #ws10\n",
    "plt.ylabel('wind speed in m/s')\n",
    "plt.xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(ws[:,scai_lat, scai_lon], bins=50)\n",
    "plt.ylabel('wind speed in m/s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECMWF data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit ECMWF data to ERA5-PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate ECMWF data to fit on ERA5 data grid\n",
    "#transform ECMWF data with ERA5-PCA \n",
    "\n",
    "from scipy import interpolate\n",
    "'''\n",
    "import ecmwf.data as ecdata\n",
    "from magpye import GeoMap\n",
    "from ecmwf.opendata import Client\n",
    "\n",
    "client = Client(source=\"ecmwf\")\n",
    "\n",
    "client.retrieve(\n",
    "    time=0,\n",
    "    stream=\"enfo\",\n",
    "    type=['cf'],\n",
    "    param=['u','v'],\n",
    "    step=[0,3,6,9],\n",
    "    levelist = 925,\n",
    "    target=\"data.grib2\",\n",
    ")\n",
    "'''\n",
    "\n",
    "data = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "\n",
    "lons_ecmwf = np.array(data.variables['longitude'][:])  # longitude 900\n",
    "lats_ecmwf = np.array(data.variables['latitude'][:])  # latitude 451\n",
    "time_ecmwf = np.array(data.variables['time'])\n",
    "u_ecmwf = np.array(data.variables['u']) #4, lons, lats\n",
    "v_ecmwf = np.array(data.variables['v']) #4, lons, lats\n",
    "\n",
    "ws_ecmwf = np.array(np.sqrt(u_ecmwf*u_ecmwf+v_ecmwf*v_ecmwf))\n",
    "\n",
    "#only use small grid (approx. ERA5)\n",
    "\n",
    "max_idx_lats = np.argmax(lats_ecmwf<np.array(lats[0])) #largest\n",
    "min_idx_lats = np.argmax(lats_ecmwf<np.array(lats[-1]) ) #smallest\n",
    "max_idx_lons = np.argmax(lons_ecmwf>np.array(lons[0])) #largest\n",
    "min_idx_lons = np.argmax(lons_ecmwf>np.array(lons[-1]) ) #smallest\n",
    "\n",
    "x = lons_ecmwf[max_idx_lons-1:min_idx_lons+1]\n",
    "y = lats_ecmwf[max_idx_lats-1:min_idx_lats+1]\n",
    "X, Y = np.meshgrid(x, y)\n",
    "z = ws_ecmwf[0,max_idx_lats-1:min_idx_lats+1,max_idx_lons-1:min_idx_lons+1]\n",
    "\n",
    "x2 = lons #era5\n",
    "y2 = lats #era5\n",
    "f = interpolate.interp2d(x, y, z, kind='cubic')\n",
    "z2 = f(x2, y2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].pcolormesh(X, Y, z)\n",
    "X2, Y2 = np.meshgrid(x2, y2)\n",
    "ax[1].pcolormesh(X2, Y2, z2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_0c = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "\n",
    "data_1 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_1c = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "\n",
    "data_2 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_2c = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "\n",
    "data_3 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_3c = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ecmwf_0 = (data_0.variables['u'])  #(50, 31, 3, 451, 900)\n",
    "v_ecmwf_0 = (data_0.variables['v'])  #(ensemble_nr, step, hPa, lat, long)\n",
    "u_ecmwf_0c = (data_0c.variables['u'])\n",
    "v_ecmwf_0c = (data_0c.variables['v'])\n",
    "\n",
    "u_ecmwf_1 = (data_1.variables['u'])\n",
    "v_ecmwf_1 = (data_1.variables['v'])\n",
    "u_ecmwf_1c = (data_1c.variables['u'])\n",
    "v_ecmwf_1c = (data_1c.variables['v'])\n",
    "\n",
    "u_ecmwf_2 = (data_2.variables['u'])\n",
    "v_ecmwf_2 = (data_2.variables['v'])\n",
    "u_ecmwf_2c = (data_2c.variables['u'])\n",
    "v_ecmwf_2c = (data_2c.variables['v'])\n",
    "\n",
    "u_ecmwf_3 = (data_3.variables['u'])\n",
    "v_ecmwf_3 = (data_3.variables['v'])\n",
    "u_ecmwf_3c = (data_3c.variables['u'])\n",
    "v_ecmwf_3c = (data_3c.variables['v'])\n",
    "\n",
    "lat0 = 97\n",
    "lon0 = 475\n",
    "\n",
    "u0 = u_ecmwf_0[:, :, 1, lat0, lon0] #ensemble_nr, step, hPa, lat, long\n",
    "v0 = v_ecmwf_0[:, :, 1, lat0, lon0] \n",
    "u0c = u_ecmwf_0c[:, 1, lat0, lon0]\n",
    "v0c = v_ecmwf_0c[:, 1, lat0, lon0]\n",
    "\n",
    "u1 = u_ecmwf_1[:, :, 1, lat0, lon0]\n",
    "v1 = v_ecmwf_1[:, :, 1, lat0, lon0]\n",
    "u1c = u_ecmwf_1c[:, 1, lat0, lon0]\n",
    "v1c = v_ecmwf_1c[:, 1, lat0, lon0]\n",
    "\n",
    "u2 = u_ecmwf_2[:, :, 1, lat0, lon0]\n",
    "v2 = v_ecmwf_2[:, :, 1, lat0, lon0]\n",
    "u2c = u_ecmwf_2c[:, 1, lat0, lon0]\n",
    "v2c = v_ecmwf_2c[:, 1, lat0, lon0]\n",
    "\n",
    "u3 = u_ecmwf_3[:, :, 1, lat0, lon0]\n",
    "v3 = v_ecmwf_3[:, :, 1, lat0, lon0]\n",
    "u3c = u_ecmwf_3c[:, 1, lat0, lon0]\n",
    "v3c = v_ecmwf_3c[:, 1, lat0, lon0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_ecmwf_0 = np.array(np.sqrt(u0*u0+v0*v0))\n",
    "ws_ecmwf_0c = np.array(np.sqrt(u0c*u0c+v0c*v0c))\n",
    "ws_ecmwf_1 = np.array(np.sqrt(u1*u1+v1*v1))\n",
    "ws_ecmwf_1c = np.array(np.sqrt(u1c*u1c+v1c*v1c))\n",
    "ws_ecmwf_2 = np.array(np.sqrt(u2*u2+v2*v2))\n",
    "ws_ecmwf_2c = np.array(np.sqrt(u2c*u2c+v2c*v2c))\n",
    "ws_ecmwf_3 = np.array(np.sqrt(u3*u3+v3*v3))\n",
    "ws_ecmwf_3c = np.array(np.sqrt(u3c*u3c+v3c*v3c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind speed in performance\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "wind_speed = np.linspace(0,25,51)\n",
    "performance = np.array([0, 0, 0, 0, 3, 10, 25, 49, 82, 123, 174, 240, 321, 418, 532, 664, 815, 988, 1180, 1384, 1580, 1749, 1890, 2005, 2100, 2180, 2250, 2311, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350, 2350])\n",
    "\n",
    "interp_perf = interpolate.UnivariateSpline(wind_speed, performance, s=0)\n",
    "def convert_wind_to_performance(ws):\n",
    "    return interp_perf(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction in germany for specific time\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "lat_ger_0 = 87  #Germany 87:107, 465:488\n",
    "lat_ger_1 = 107\n",
    "lon_ger0 = 465\n",
    "lon_ger1 = 489\n",
    "t_step = 8\n",
    "\n",
    "lons_ecmwf_0 = np.array(data_0.variables['longitude'][:])\n",
    "lats_ecmwf_0 = np.array(data_0.variables['latitude'][:])\n",
    "time_ecmwf_0 = np.array(data_0.variables['time'])\n",
    "\n",
    "#for t_step in range(u_ecmwf_0c.shape[0]):\n",
    "u0c_area = u_ecmwf_0c[t_step, 1, lat_ger_0:lat_ger_1, lon_ger0:lon_ger1]\n",
    "v0c_area = v_ecmwf_0c[t_step, 1, lat_ger_0:lat_ger_1, lon_ger0:lon_ger1]\n",
    "ws0c_area = np.array(np.sqrt(u0c_area*u0c_area+v0c_area*v0c_area))\n",
    "\n",
    "m = Basemap(llcrnrlon=5,llcrnrlat=47.5,urcrnrlon=17,urcrnrlat=55,\n",
    "            resolution='i', projection='tmerc', lat_0 = 0, lon_0 = 0)\n",
    "#~GERMANY llcrnrlon=5,llcrnrlat=47.5,urcrnrlon=17,urcrnrlat=55\n",
    "#~EUROPE llcrnrlon=-12,llcrnrlat=35,urcrnrlon=57,urcrnrlat=63\n",
    "\n",
    "#LON/LAT of SCAI: 50.749203582484625, 7.202800904147935\n",
    "scai_lon = 3 #ger3 #468\n",
    "scai_lat = 11 #ger11 #98\n",
    "\n",
    "lon, lat = np.meshgrid(lons_ecmwf_0[lon_ger0:lon_ger1], lats_ecmwf_0[lat_ger_0:lat_ger_1])\n",
    "xi, yi = m(lon, lat)\n",
    "cs = m.pcolor(xi, yi, np.squeeze(ws0c_area))\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary()\n",
    "m.drawcountries()\n",
    "cbar = m.colorbar(cs, location='right', pad=\"10%\")\n",
    "plt.plot(xi[scai_lat, scai_lon], yi[scai_lat, scai_lon],'ro')\n",
    "#plt.plot(xi[lat0-lat_ger_0, lon0-lon_ger0], yi[lat0-lat_ger_0, lon0-lon_ger0],'ro')\n",
    "#plt.title(\"lon: %4.1f, lat: %4.1f\" % (lons_ecmwf_0[lon0], lats_ecmwf_0[lat0]))\n",
    "tt = data_0['time'].dt.strftime(\"%Y-%m-%d %H:%Mh\").variable.values\n",
    "plt.title('wind speed in m/s') #\\n'+str(tt)+' \\n '+str(t_step*3)+' hours later')\n",
    "#plt.xlabel('longitude')\n",
    "#plt.ylabel('latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind speed comparison two days\n",
    "\n",
    "time_ecmwf_2 = data_2['time'].dt.strftime(\"%Y-%m-%d %H:%Mh\").variable.values\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "step1 = 16\n",
    "step2 = 8\n",
    "step3 = 0\n",
    "\n",
    "plt_1 = ws_ecmwf_0c[step1:]\n",
    "len1 = plt_1.shape[0]\n",
    "plt_2 = ws_ecmwf_1c[step2:step2+len1]\n",
    "plt_3 = ws_ecmwf_2c[step3:step3+len1]\n",
    "plt_time = np.linspace(0,(len1-1)*3, len1)\n",
    "\n",
    "if True: #perturbed forecasts\n",
    "    for i in range(ws_ecmwf_0.shape[0]):\n",
    "        plt_1i = ws_ecmwf_1[i, step1:]\n",
    "        plt_2i = ws_ecmwf_2[i, step2:step2+len1]\n",
    "        plt_3i = ws_ecmwf_3[i, step3:step3+len1]\n",
    "\n",
    "        plt.plot(plt_time, plt_1i, 'r', alpha = 0.3) \n",
    "        plt.plot(plt_time, plt_2i, 'g', alpha = 0.3) \n",
    "        plt.plot(plt_time, plt_3i, 'b', alpha = 0.3)\n",
    "\n",
    "plt.plot(plt_time, plt_1, 'rx-', linewidth=2, label='-2 days, in 48h')\n",
    "plt.plot(plt_time, plt_2, 'gx-', linewidth=2, label='-1 day, in 24h') \n",
    "plt.plot(plt_time, plt_3, 'bx-', linewidth=2, label='-0 days, in 0h')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('time_steps=0 corresponds to '+str(time_ecmwf_2))\n",
    "plt.xticks(plt_time)\n",
    "plt.xlabel('time_steps')\n",
    "plt.ylabel('wind speed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind speed comparison three days\n",
    "time_ecmwf_3 = data_3['time'].dt.strftime(\"%Y-%m-%d %H:%Mh\").variable.values\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "step0 = 24\n",
    "step1 = 16\n",
    "step2 = 8\n",
    "step3 = 0\n",
    "\n",
    "plt_0 = ws_ecmwf_0c[step0:]\n",
    "len0 = plt_0.shape[0]\n",
    "plt_1 = ws_ecmwf_1c[step1:step1+len0]\n",
    "plt_2 = ws_ecmwf_2c[step2:step2+len0]\n",
    "plt_3 = ws_ecmwf_3c[step3:step3+len0]\n",
    "plt_time = np.linspace(0,(len0-1)*3, len0)\n",
    "\n",
    "if True: #perturbed forecasts\n",
    "    for i in range(ws_ecmwf_0.shape[0]):\n",
    "        plt_0i = ws_ecmwf_0[i, step0:]\n",
    "        plt_1i = ws_ecmwf_1[i, step1:step1+len0]\n",
    "        plt_2i = ws_ecmwf_2[i, step2:step2+len0]\n",
    "        plt_3i = ws_ecmwf_3[i, step3:step3+len0]\n",
    "\n",
    "        plt.plot(plt_time, plt_0i, 'm', alpha = 0.3)\n",
    "        plt.plot(plt_time, plt_1i, 'r', alpha = 0.3) \n",
    "        plt.plot(plt_time, plt_2i, 'g', alpha = 0.3) \n",
    "        plt.plot(plt_time, plt_3i, 'b', alpha = 0.3)\n",
    "\n",
    "plt.plot(plt_time, plt_0, 'mx-', linewidth=2, label='-3 days, in 72h')\n",
    "plt.plot(plt_time, plt_1, 'rx-', linewidth=2, label='-2 days, in 48h')\n",
    "plt.plot(plt_time, plt_2, 'gx-', linewidth=2, label='-1 day, in 24h') \n",
    "plt.plot(plt_time, plt_3, 'bx-', linewidth=2, label='-0 days, in 0h')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('time_steps=0 corresponds to '+str(time_ecmwf_3))\n",
    "plt.xticks(plt_time)\n",
    "plt.xlabel('time_steps')\n",
    "plt.ylabel('wind speed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance comparison three days\n",
    "\n",
    "time_ecmwf_3 = data_3['time'].dt.strftime(\"%Y-%m-%d %H:%Mh\").variable.values\n",
    "\n",
    "step0 = 24\n",
    "step1 = 16\n",
    "step2 = 8\n",
    "step3 = 0\n",
    "\n",
    "plt_0 = ws_ecmwf_0c[step0:]\n",
    "len0 = plt_0.shape[0]\n",
    "plt_1 = ws_ecmwf_1c[step1:step1+len0]\n",
    "plt_2 = ws_ecmwf_2c[step2:step2+len0]\n",
    "plt_3 = ws_ecmwf_3c[step3:step3+len0]\n",
    "plt_time = np.linspace(0,(len0-1)*3, len0)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "if True: #perturbed forecasts\n",
    "    for i in range(ws_ecmwf_0.shape[0]):\n",
    "        plt_0i = ws_ecmwf_0[i, step0:]\n",
    "        plt_1i = ws_ecmwf_1[i, step1:step1+len0]\n",
    "        plt_2i = ws_ecmwf_2[i, step2:step2+len0]\n",
    "        plt_3i = ws_ecmwf_3[i, step3:step3+len0]\n",
    "\n",
    "        plt.plot(plt_time, interp_perf(plt_0i), 'm', alpha = 0.3)\n",
    "        plt.plot(plt_time, interp_perf(plt_1i), 'r', alpha = 0.3) \n",
    "        plt.plot(plt_time, interp_perf(plt_2i), 'g', alpha = 0.3) \n",
    "        plt.plot(plt_time, interp_perf(plt_3i), 'b', alpha = 0.3)\n",
    "\n",
    "plt.plot(plt_time, interp_perf(plt_0), 'mx-', linewidth=2, label='-3 days, in 72h')\n",
    "plt.plot(plt_time, interp_perf(plt_1), 'rx-', linewidth=2, label='-2 days, in 48h')\n",
    "plt.plot(plt_time, interp_perf(plt_2), 'gx-', linewidth=2, label='-1 day, in 24h')\n",
    "plt.plot(plt_time, interp_perf(plt_3), 'bx-', linewidth=2, label='-0 days, in 0h')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(plt_time)\n",
    "plt.title('time_steps=0 corresponds to '+str(time_ecmwf_3))\n",
    "plt.xlabel('time_steps')\n",
    "plt.ylabel('generation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram three days \n",
    "\n",
    "step0 = 24 #in 72h\n",
    "step1 = 16 #in 48h\n",
    "step2 = 8 #in 24h\n",
    "step3 = 0 #now\n",
    "\n",
    "plt_0 = ws_ecmwf_0[:,step0]\n",
    "plt_1 = ws_ecmwf_1[:,step1]\n",
    "plt_2 = ws_ecmwf_2[:,step2]\n",
    "plt_3 = ws_ecmwf_3[:,step3]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(plt_0, bins=20, alpha = 0.4, label='-3 days, in 72h')\n",
    "plt.hist(plt_1, bins=20, alpha = 0.4, label='-2 days, in 48h')\n",
    "plt.hist(plt_2, bins=20, alpha = 0.4, label='-1 day, in 24h')\n",
    "plt.hist(plt_3, bins=20, alpha = 0.4, label='-0 days, in 0h')\n",
    "plt.legend()\n",
    "plt.title('time_steps=0 corresponds to '+str(time_ecmwf_3))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(interp_perf(plt_0), bins=20, alpha = 0.4, label='-3 days, in 72h')\n",
    "plt.hist(interp_perf(plt_1), bins=20, alpha = 0.4, label='-2 days, in 48h')\n",
    "plt.hist(interp_perf(plt_2), bins=20, alpha = 0.4, label='-1 day, in 24h')\n",
    "plt.hist(interp_perf(plt_3), bins=20, alpha = 0.4, label='-0 days, in 0h')\n",
    "plt.legend()\n",
    "plt.title('time_steps=0 corresponds to '+str(time_ecmwf_3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plot\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime as dt \n",
    "\n",
    "timelabel0 = np.datetime_as_string((data_3['time'].values - np.timedelta64(step0*3, 'h')), unit='D')\n",
    "timelabel1 = np.datetime_as_string((data_3['time'].values - np.timedelta64(step1*3, 'h')), unit='D')\n",
    "timelabel2 = np.datetime_as_string((data_3['time'].values - np.timedelta64(step2*3, 'h')), unit='D')\n",
    "timelabel3 = np.datetime_as_string((data_3['time'].values - np.timedelta64(step3*3, 'h')), unit='D')\n",
    "\n",
    "plt.figure()\n",
    "sns.violinplot(data=[ws_ecmwf_0[:,step0], ws_ecmwf_1[:,step1], ws_ecmwf_2[:,step2], ws_ecmwf_3[:,step3]]).set_xticklabels([timelabel0, timelabel1, timelabel2, timelabel3])\n",
    "plt.title(data_3['time'].dt.strftime(\"%d.%m.%Y %H:%Mh\").variable.values)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longer time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control forecast \n",
    "\n",
    "data_90 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_84 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_78 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "#data_72 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "#data_66 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "#data_60 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "#data_54 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_48 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_42 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_36 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_30 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_24 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_18 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_12 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_6 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})\n",
    "data_0 = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'cf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction change over time for 24.12.2023 18h\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "lat_ger_0 = 87  #Germany 87:107, 465:488\n",
    "lat_ger_1 = 108\n",
    "lon_ger0 = 465\n",
    "lon_ger1 = 488\n",
    "\n",
    "scai_lon = 3 \n",
    "scai_lat = 11\n",
    "\n",
    "data_list = [data_90, data_84, data_78, #data_72, data_66, data_60, data_54, \n",
    "             data_48, data_42, data_36, data_30, data_24, data_18, data_12, data_6, data_0]\n",
    "\n",
    "#t_step_list = [90, 84, 78, 72, 66, 60, 54, 48, 42, 36, 30, 24, 18, 12, 6, 0]\n",
    "t_step_list = [30, 28, 26, #24, 22, 20, 18, \n",
    "               16, 14, 12, 10, 8, 6, 4, 2, 0]\n",
    "\n",
    "for i, k in enumerate(data_list):\n",
    "\n",
    "    lons_ecmwf_list = np.array(k.variables['longitude'][:])\n",
    "    lats_ecmwf_list = np.array(k.variables['latitude'][:])\n",
    "    u_ecmwf_list = (k.variables['u'])\n",
    "    v_ecmwf_list = (k.variables['v'])\n",
    "    #time_ecmwf_list = k['time'].dt.strftime(\"%Y%m%d_%Hh\").variable.values\n",
    "    \n",
    "    t_step = t_step_list[i]\n",
    "    u_area = u_ecmwf_list[t_step, 1, lat_ger_0:lat_ger_1, lon_ger0:lon_ger1]\n",
    "    v_area = v_ecmwf_list[t_step, 1, lat_ger_0:lat_ger_1, lon_ger0:lon_ger1]\n",
    "    ws_area = np.array(np.sqrt(u_area*u_area+v_area*v_area))\n",
    "\n",
    "    m = Basemap(llcrnrlon=5.8,llcrnrlat=47,urcrnrlon=15.8,urcrnrlat=55,\n",
    "                resolution='i', projection='tmerc', lat_0 = 0, lon_0 = 10)\n",
    "\n",
    "    lon, lat = np.meshgrid(lons_ecmwf_list[lon_ger0:lon_ger1], lats_ecmwf_0[lat_ger_0:lat_ger_1])\n",
    "    xi, yi = m(lon, lat)\n",
    "    cs = m.pcolor(xi, yi, np.squeeze(ws_area), vmin=0, vmax=30)\n",
    "\n",
    "    m.drawcoastlines()\n",
    "    m.drawmapboundary()\n",
    "    m.drawcountries()\n",
    "    cbar = m.colorbar(cs, location='right', pad=\"10%\")\n",
    "    plt.plot(xi[scai_lat, scai_lon], yi[scai_lat, scai_lon],'ro')\n",
    "    plt.title('wind speed in m/s')\n",
    "    #plt.xlabel('longitude')\n",
    "    #plt.ylabel('latitude')\n",
    "    plt.savefig('/Users/angelina/Documents/eworld/wind_speed_'+str(i)+'.jpg', dpi=1500) #(time_ecmwf_list)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturbed forecast\n",
    "\n",
    "data_90p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_84p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_78p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "#data_72p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231221_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "#data_66p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "#data_60p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "#data_54p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_48p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231222_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_42p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_36p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_30p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_24p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231223_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_18p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_0h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_12p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_6h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_6p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_12h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})\n",
    "data_0p = xr.open_dataset('/Users/angelina/Documents/Arbeit/RiVaPy/notebooks/tools/data/ECMWF/20231224_18h_data.grib2', engine='cfgrib', filter_by_keys={'dataType': 'pf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plot\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "lat_ger_0 = 87  #Germany 87:107, 465:488\n",
    "lat_ger_1 = 108\n",
    "lon_ger0 = 465\n",
    "lon_ger1 = 488\n",
    "\n",
    "scai_lon = 3 \n",
    "scai_lat = 11\n",
    "\n",
    "data_list = [#data_90, data_84, data_78, #data_72, data_66, data_60, data_54, \n",
    "             data_48p, data_42p, data_36p, data_30p, data_24p, data_18p, data_12p, data_6p, data_0p] \n",
    "t_step_list = [#30, 28, 26, #24, 22, 20, 18, \n",
    "               16, 14, 12, 10, 8, 6, 4, 2, 0] \n",
    "ws_list = []\n",
    "timelabel_list = []\n",
    "\n",
    "for i, k in enumerate(data_list):\n",
    "\n",
    "    t_step = t_step_list[i]\n",
    "    u_area = (k.variables['u'])[:, t_step, 1, scai_lat, scai_lon]\n",
    "    v_area = (k.variables['v'])[:, t_step, 1, scai_lat, scai_lon]\n",
    "\n",
    "    ws_list.append(np.sqrt(u_area*u_area+v_area*v_area))\n",
    "    timelabel_list.append(k['time'].dt.strftime(\"%Y-%m-%d %Hh\").values)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.violinplot(data=ws_list).set_xticklabels(timelabel_list)\n",
    "plt.title(data_0['time'].dt.strftime(\"%Y-%m-%d %Hh\").values)\n",
    "plt.tight_layout() \n",
    "plt.savefig('/Users/angelina/Documents/eworld/wind_speed_violinplot.jpg', dpi=1500) #_241223_18h\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rivapy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
